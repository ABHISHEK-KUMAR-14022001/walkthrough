# Terraform EKS Infrastructure Review

## Architecture Overview

```mermaid
graph TB
    subgraph "VPC (10.0.0.0/16)"
        subgraph "Public Subnets"
            BASTION["üñ•Ô∏è Bastion Host<br/>(SSM Access)"]
            NAT["üåê NAT Gateway"]
            IGW["üö™ Internet Gateway"]
        end
        
        subgraph "Private Subnets"
            subgraph "EKS Cluster"
                CP["üéõÔ∏è Control Plane"]
                FE["Frontend Nodes"]
                BE["Backend Nodes"]
                SYS["System Nodes"]
            end
            
            DB["üóÑÔ∏è Database VM<br/>(PostgreSQL, Redis, ES)"]
        end
    end
    
    IGW --> NAT
    NAT --> FE & BE & SYS
    BE --> DB
    FE --> DB
    BASTION --> CP
```

---

## ‚úÖ What's Correct

| Component | Status | Details |
|-----------|--------|---------|
| **VPC Setup** | ‚úÖ | DNS support/hostnames enabled |
| **Public/Private Subnets** | ‚úÖ | Proper CIDR allocation with correct tagging for K8s load balancers |
| **NAT Gateway** | ‚úÖ | Enables outbound internet for private subnets |
| **EKS Cluster** | ‚úÖ | Private endpoint only (secure) |
| **Node Groups** | ‚úÖ | 3 node groups with proper taints/labels |
| **Bastion Host** | ‚úÖ | SSM-only access (no SSH ports exposed) |
| **Database VM** | ‚úÖ | Private subnet, no public IP |
| **Security Groups** | ‚úÖ | Proper ingress rules for PostgreSQL (5432), Redis (6379), Elasticsearch (9200) from EKS nodes |

---

## ‚ö†Ô∏è Issues Found

### 1. **CRITICAL: EKS Access Entry Error** (Already Fixed)
The `access_config` block was missing from the EKS cluster. I've already added this:

```hcl
access_config {
  authentication_mode = "API_AND_CONFIG_MAP"
}
```

> [!CAUTION]
> Since your cluster already exists, you'll need to **recreate the cluster** for this change to take effect. The authentication mode cannot be changed after cluster creation.

---

### 2. **CRITICAL: EKS Version 1.34 Does Not Exist**

In [eks.tf](file:///c:/Users/abhiw/OneDrive/Desktop/devlopment/aws/prod_eks/eks.tf), line 25:

```hcl
version  = "1.34"  # ‚ùå Invalid - latest is 1.31 as of Jan 2026
```

**Fix**: Change to a valid version like `1.31`:
```diff
- version  = "1.34"
+ version  = "1.31"
```

---

### 3. **CRITICAL: Database VM Missing VPC Endpoints for SSM**

Your database VM is in a **private subnet with VPC-only egress**, but SSM requires HTTPS access to AWS endpoints. Without VPC endpoints, SSM Session Manager won't work.

**Add these VPC endpoints** to enable SSM on the private database VM:

```hcl
resource "aws_vpc_endpoint" "ssm" {
  vpc_id              = aws_vpc.eks_vpc.id
  service_name        = "com.amazonaws.${var.region}.ssm"
  vpc_endpoint_type   = "Interface"
  subnet_ids          = aws_subnet.private[*].id
  security_group_ids  = [aws_security_group.db_vm_sg.id]
  private_dns_enabled = true
}

resource "aws_vpc_endpoint" "ssmmessages" {
  vpc_id              = aws_vpc.eks_vpc.id
  service_name        = "com.amazonaws.${var.region}.ssmmessages"
  vpc_endpoint_type   = "Interface"
  subnet_ids          = aws_subnet.private[*].id
  security_group_ids  = [aws_security_group.db_vm_sg.id]
  private_dns_enabled = true
}

resource "aws_vpc_endpoint" "ec2messages" {
  vpc_id              = aws_vpc.eks_vpc.id
  service_name        = "com.amazonaws.${var.region}.ec2messages"
  vpc_endpoint_type   = "Interface"
  subnet_ids          = aws_subnet.private[*].id
  security_group_ids  = [aws_security_group.db_vm_sg.id]
  private_dns_enabled = true
}
```

**Also add ingress rule** to the DB security group for HTTPS from VPC endpoints:

```hcl
resource "aws_security_group_rule" "db_https_for_ssm" {
  type              = "ingress"
  from_port         = 443
  to_port           = 443
  protocol          = "tcp"
  cidr_blocks       = [var.vpc_cidr]
  security_group_id = aws_security_group.db_vm_sg.id
  description       = "HTTPS for SSM VPC endpoints"
}
```

---

## ‚úÖ Connectivity Analysis: EKS Pods ‚Üí Database VM

### Will Your Pods Connect Successfully?

**YES** ‚úÖ ‚Äî Your security groups are correctly configured.

| Service | Port | Security Group Rule | Status |
|---------|------|---------------------|--------|
| PostgreSQL | 5432 | `db_postgres_from_nodes` allows from `eks_node_sg` | ‚úÖ |
| Redis | 6379 | `db_redis_from_nodes` allows from `eks_node_sg` | ‚úÖ |
| Elasticsearch | 9200 | `db_elasticsearch_from_nodes` allows from `eks_node_sg` | ‚úÖ |

### How to Connect from Pods

After deployment, get the database VM's private IP from Terraform outputs:

```bash
terraform output db_vm_private_ip
```

Then configure your application environment variables:

```yaml
# Example Kubernetes ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-config
data:
  POSTGRES_HOST: "<db_vm_private_ip>"
  POSTGRES_PORT: "5432"
  REDIS_HOST: "<db_vm_private_ip>"
  REDIS_PORT: "6379"
  ELASTICSEARCH_HOST: "http://<db_vm_private_ip>:9200"
```

---

## Recommended Next Steps

1. **Fix EKS version** (Change `1.34` ‚Üí `1.31`)
2. **Destroy and recreate cluster** (for `access_config` to take effect)
3. **Add VPC endpoints** for SSM to database VM (if you want SSM access)
4. **Run `terraform apply`**
5. **Install databases** on the DB VM via SSM:
   - PostgreSQL
   - Redis
   - Elasticsearch

---

## Summary

| Category | Status |
|----------|--------|
| VPC & Networking | ‚úÖ Correct |
| EKS Cluster | ‚ö†Ô∏è Fix version + recreate for access_config |
| Node Groups | ‚úÖ Correct |
| Database Connectivity | ‚úÖ Will work from pods |
| SSM for DB VM | ‚ö†Ô∏è Needs VPC endpoints |
